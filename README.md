# AI Portfolio ‚Äì Interactive Candidate Showcase

An end‚Äëto‚Äëend, minimal yet production‚Äëready showcase of an AI Software Engineer profile. Visitors chat with a model grounded in curated profile data, explore a CV, view skill stats, and get dynamic follow‚Äëup questions ‚Äì all while applying pragmatic safeguards (PII handling, validation, clean architecture, JSON‚Äëstructured LLM responses).

> FastAPI backend + Streamlit frontend. Clean boundaries. Human‚Äëfriendly answers. Small footprint. Easy to deploy.

---
## ‚ú® Highlights
- **Conversational Profile Chat** ‚Äì Answers always in first‚Äëperson voice ("I") with curated highlights.
- **Follow‚ÄëUp Question Suggestions** ‚Äì Injected after each answer (backend logic, not LLM hallucination).
- **Profile Grounding** ‚Äì Combines narrative markdown + structured JSON.
- **PII Policy** ‚Äì Regex detector; block or mask based on severity threshold (configurable).
- **Strict JSON LLM Contract** ‚Äì Schema‚Äëvalidated responses reduce parsing surprises.
- **Separation of Concerns** ‚Äì Domain ports, use cases, infrastructure adapters, presentation layer.
- **Fast Startup & Lean Dependencies** ‚Äì No ORM, no database, file‚Äëbased profile.
- **Deploy Friendly** ‚Äì Works on Render (backend) + Streamlit Cloud (frontend) out of the box.

---
## üß± Architecture Overview
```
frontend/ (Streamlit) --> calls --> FastAPI /v1/chat
                                           |
                           +-------------------------------+
                           |  Application Layer            |
User Input --> Controller -> Use Case (AnswerQuestion) ----> LLM Service (OpenAI)
                           |        |                       ^
                           |        +-> PII Processing      |
                           |        +-> Follow-up selection |
                           +-------------------------------+
                                  |                
                                  v
                             Profile Repository (file-based)
```
Supporting layers:
- `domain/` ‚Äì Entities + errors + ports (LLM, profile repo, PII detector)
- `infrastructure/` ‚Äì OpenAI client + regex PII detector + file repo
- `application/` ‚Äì Use cases + follow-up selection
- `presentation/` ‚Äì FastAPI router + error handlers
- `frontend/` ‚Äì Streamlit pages (chat, CV, stats)

---
## ‚öôÔ∏è Tech Stack
| Layer      | Tools |
|------------|-------|
| Backend    | FastAPI, Uvicorn, Pydantic v2, OpenAI SDK, Tenacity |
| Frontend   | Streamlit (multi‚Äëpage + navigation), Requests |
| Testing    | Pytest |
| Infra Ops  | Render, Streamlit Cloud |

---
## üöÄ Quick Start (Local)
Backend (API):
```
cd backend
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\\Scripts\\activate
pip install -r requirements.txt
export OPENAI_API_KEY=sk-...   # set your key
uvicorn start:app --reload
```
Frontend (Streamlit):
```
cd frontend
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
export BACKEND_URL=http://127.0.0.1:8000
streamlit run streamlit_app.py
```
Visit: http://localhost:8501

---
## üß† LLM Response Contract
Backend sends a system prompt enforcing a JSON schema derived from the `Answer` Pydantic model:
```json
{
  "type": "object",
  "properties": {
    "answer": {"type": "string"},
    "highlights": {"type": "array"},
    "follow_up_questions": {"type": "array"}
  },
  "required": ["answer","highlights","follow_up_questions"]
}
```
If decoding fails, raw content is wrapped into a fallback `Answer` with empty arrays.

---
## üõ£Ô∏è Possible Next Steps
- Add analytics/logging (token counts, latency histograms)
- Rate limiting / API key auth layer
- Deterministic follow-up selection (avoid repeats)
- Richer skill stats (charts powered from structured profile JSON)
- Multi-model fallback or streaming responses

---
## ‚ôªÔ∏è Rotating the Exposed Key
An OpenAI key was once committed. Rotate it in the OpenAI dashboard, update environment vars, and ensure the old key is revoked.

---
## üìÑ License
MIT (see `LICENSE`).

---
## üôå Acknowledgements
Built as a concise demonstration of clean layering + LLM grounding with minimal overhead.

Enjoy exploring.
